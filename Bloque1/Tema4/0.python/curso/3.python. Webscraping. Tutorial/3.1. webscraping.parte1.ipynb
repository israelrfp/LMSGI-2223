{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Python Web Scraping Tutorial y proyecto de ejemplo\n",
    "\n",
    "En este tutorial de raspado web de Python, profundizaremos en lo que hace de Python el lenguaje número uno en esta área.\n",
    "\n",
    "Abordaremos esto como una combinación de introducción práctica y explicación de bajo nivel sobre los temas más importantes de web scraping, como cómo usar clientes HTTP de manera efectiva y analizar código HTML usando selectores CSS y XPath.\n",
    "\n",
    "Cubriremos estos temas principales:\n",
    "\n",
    "Protocolo HTTP: qué son las solicitudes y las respuestas\n",
    "Análisis de HTML: cómo extraer datos de archivos HTML raspados.\n",
    "Finalmente, solidificaremos nuestro conocimiento con un proyecto de ejemplo extrayendo datos de la lista de trabajos de remotepython.com/jobs/ , un tablero de lista de trabajos para trabajos remotos de Python.\n",
    "\n",
    "En este tutorial de raspado web de Python, profundizaremos en lo que hace de Python el lenguaje número uno en esta área.\n",
    "\n",
    "Abordaremos esto como una combinación de introducción práctica y explicación de bajo nivel sobre los temas más importantes de web scraping, como cómo usar clientes HTTP de manera efectiva y analizar código HTML usando selectores CSS y XPath.\n",
    "\n",
    "Cubriremos estos temas principales:\n",
    "\n",
    "Protocolo HTTP: qué son las solicitudes y las respuestas\n",
    "Análisis de HTML: cómo extraer datos de archivos HTML raspados.\n",
    "Finalmente, solidificaremos nuestro conocimiento con un proyecto de ejemplo extrayendo datos de la lista de trabajos de remotepython.com/jobs/ , un tablero de lista de trabajos para trabajos remotos de Python.\n",
    "\n",
    "**¿Qué es el raspado web?**\n",
    "Una de las mayores revoluciones del siglo XXI es darse cuenta de lo valiosos que pueden ser los datos, ¡e Internet está lleno de datos públicos gratuitos!\n",
    "\n",
    "El raspado web es un proceso automatizado para recopilar datos web públicos. Hay miles de razones por las que uno podría querer recopilar estos datos públicos, como encontrar empleados potenciales o recopilar inteligencia competitiva. En ScrapFly hicimos una investigación exhaustiva sobre las aplicaciones de web scraping, y puede encontrar nuestros hallazgos aquí en nuestra página de casos de uso de web scraping .\n",
    "\n",
    "Para raspar un sitio web con python, generalmente nos enfrentamos a dos tipos de problemas: recopilar los datos públicos disponibles en línea y luego analizar estos datos para obtener información estructurada del producto.\n",
    "\n",
    "Entonces, ¿cómo extraer datos de un sitio web usando Python? En este artículo, cubriremos todo lo que necesita saber, ¡vamos a sumergirnos!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración\n",
    "En este tutorial, cubriremos varias bibliotecas populares de web scraping:\n",
    "\n",
    "* httpx : biblioteca de cliente HTTP, más comúnmente utilizada en web scraping. Otra alternativa popular para esto es la biblioteca de solicitudes , aunque nos quedaremos con httpxella, ya que es mucho más adecuada para el web scraping.\n",
    "* beauitifulsoup4 : usaremos BeautifulSoup para el análisis de HTML.\n",
    "\n",
    "Podemos instalar todas estas bibliotecas usando el pip installcomando de la consola: \n",
    "```bash\n",
    "pip install httpx request parsel bs4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inicio rápido\n",
    "## Antes de profundizar, echemos un vistazo rápido a un web scraper simple:\n",
    "\n",
    "import httpx\n",
    "from parsel import Selector\n",
    "\n",
    "### Retrieve html page\n",
    "response = httpx.get(\"https://www.remotepython.com/jobs/\")\n",
    "###  check whether request was a success\n",
    "assert response.status_code == 200\n",
    "### parse HTML for specific information:\n",
    "selector = Selector(text=response.text)\n",
    "for job in selector.css('.box-list .item'):\n",
    "    title = job.css('h3 a::text').get()\n",
    "    relative_url = job.css('h3 a::attr(href)').get()\n",
    "    print(title)\n",
    "    print(response.url.join(relative_url))\n",
    "    print('--------------------------')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamentos de HTTP\n",
    "Para recopilar datos de un recurso público, primero debemos establecer una conexión con él.\n",
    "\n",
    "La mayor parte de la web se sirve a través de HTTP, que es bastante simple:\n",
    "nosotros (el cliente) enviamos una solicitud al sitio web (el servidor) para un documento específico. El servidor procesa la solicitud y responde con una respuesta que contendrá los datos web o un mensaje de error. ¡Un intercambio muy directo!\n",
    "\n",
    "En una petición enviamos un objeto de solicitud que consiste en un método (también conocido como tipo), ubicación y encabezados.\n",
    "A su vez, recibimos un objeto de respuesta que consta de un código de estado , encabezados y el contenido del documento en sí.\n",
    "\n",
    "Echemos un vistazo rápido a cada uno de estos componentes, qué significan y cómo son relevantes en el web scraping.\n",
    "\n",
    "**Solicitudes y respuestas**\n",
    "Cuando se trata de web scraping, no necesitamos saber exactamente cada pequeño detalle sobre HTTP, así que echemos un vistazo a los elementos esenciales de web scraping.\n",
    "\n",
    "**Métodos de solicitud**\n",
    "Las solicitudes HTTP se dividen convenientemente en unos pocos tipos (llamados métodos) que realizan funciones distintas. Los tipos más comunes utilizados en web scraping y web en general son:\n",
    "\n",
    "* GET:  Las solicitudes tienen por objeto solicitar un documento.\n",
    "* POST: Las solicitudes están destinadas a solicitar un documento mediante el envío de un documento.\n",
    "* HEAD: Las solicitudes están destinadas a solicitar metainformación de documentos.\n",
    "\n",
    "En web scraping, principalmente usaremos solicitudes de tipo GET ya que queremos recuperar los documentos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
